{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from UWM Libraries\n",
    "link: https://collections.lib.uwm.edu/digital/collection/agsphoto/search/searchterm/Still%20Image/field/type/mode/exact/conn/and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "image_uri = lambda  id, collection: f'https://collections.lib.uwm.edu/digital/iiif/{collection}/{id}/square/360,360/0/default.jpg'\n",
    "images_uri = lambda page: f'https://collections.lib.uwm.edu/digital/api/search/collection/agsafrica!agsphoto!agseurope!agsnorth!agsoceania!ags_south/page/{page}/maxRecords/2000'\n",
    "\n",
    "data = dict(\n",
    "    id= [],\n",
    "    title= [],\n",
    "    collection= [],\n",
    "    filetype= [],\n",
    "    date= []\n",
    ")\n",
    "\n",
    "page=1\n",
    "max_pages=1\n",
    "while True:\n",
    "    response = requests.get(images_uri(page))\n",
    "    if response.status_code == 200:\n",
    "        resp = response.json()\n",
    "    \n",
    "    if not resp['items']:\n",
    "        break\n",
    "\n",
    "    for item in resp['items']:\n",
    "        collection = item['collectionAlias']\n",
    "        id = int(item['itemId'])\n",
    "        filetype = item['filetype']\n",
    "        title = item['title']\n",
    "\n",
    "        date = None\n",
    "        for row in item['metadataFields']:\n",
    "            if row['field'] == 'date':\n",
    "                date = row['value']\n",
    "        date\n",
    "\n",
    "        data['id'].append(id)\n",
    "        data['title'].append(title)\n",
    "        data['collection'].append(collection)\n",
    "        data['filetype'].append(filetype)\n",
    "        data['date'].append(date)\n",
    "\n",
    "    page+=1\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('all_images.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting images metadata from web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [28:55,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('all_images.csv')\n",
    "\n",
    "image_uri = lambda  id, collection: f'https://collections.lib.uwm.edu/digital/iiif/{collection}/{id}/square/360,360/0/default.jpg'\n",
    "output_dir = './images'\n",
    "\n",
    "step = 1 # must be bigger than 1\n",
    "for _, row in tqdm(df.loc[1_000*(step-1):1_000*step, ['id', 'collection', 'filetype']].iterrows()):\n",
    "    id, collection, filetype = row\n",
    "\n",
    "    url = image_uri(id, collection)\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        image_path = os.path.join(output_dir, f\"{collection}_{id}.{filetype}\")\n",
    "        \n",
    "        with open(image_path, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "    \n",
    "    response.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubert-units",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
